{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "from os import mkdir\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from data import make_data_loader\n",
    "from engine.trainer import do_train\n",
    "from modeling import build_model\n",
    "from solver import make_optimizer, WarmupMultiStepLR\n",
    "from layers import make_loss\n",
    "from config import cfg\n",
    "from utils.logger import setup_logger\n",
    "from utils.feats_pca import feats_map_pca_projection,feats_pca_projection\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import cv2\n",
    "from imageio_ffmpeg import write_frames\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from apex import amp\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "torch.cuda.set_device(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = '/data/NFS/wmy/training'\n",
    "files = [ i    for i in os.listdir(train_folder) if os.path.isdir(os.path.join(train_folder,i))]\n",
    "\n",
    "#files = ['data19']\n",
    "for data in files:\n",
    "    if data =='data19':\n",
    "        continue\n",
    "    model_path = os.path.join(train_folder,data)\n",
    "    fns = [ int(i.split('_')[2].split('.')[0])    for i in os.listdir(model_path) if 'nr_model_' in i]\n",
    "    if len(fns)==0:\n",
    "        continue\n",
    "    fns.sort()\n",
    "    fns = fns[-1]\n",
    "    print(data,fns)\n",
    "    render(model_path,fns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(model_path, epoch):\n",
    "    para_file = 'nr_model_%d.pth' % epoch\n",
    "\n",
    "\n",
    "    cfg.merge_from_file(os.path.join(model_path,'configs.yml'))\n",
    "    #cfg.INPUT.SIZE_TRAIN = [1000,750]\n",
    "    #cfg.INPUT.SIZE_TEST = [1000,750]\n",
    "    cfg.SOLVER.IMS_PER_BATCH = 1\n",
    "    #cfg.freeze()\n",
    "    \n",
    "    test_loader, dataset = make_data_loader(cfg, is_train=True)\n",
    "    \n",
    "    model = build_model(cfg, isTrain = False)\n",
    "    a = torch.load(os.path.join(model_path,para_file),map_location='cpu')\n",
    "    model.pcpr_parameters.setPointNum(a['pcpr_parameters.p_parameters'].size(1))\n",
    "    model.load_state_dict(a)\n",
    "    #model.eval()\n",
    "    model = model.cuda()\n",
    "    #optimizer = make_optimizer(cfg, model)\n",
    "    #model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\")\n",
    "    \n",
    "    feature_maps = []\n",
    "    tars = []\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    for batch in test_loader:\n",
    "        in_points = batch[1].cuda()\n",
    "        K = batch[2].cuda()\n",
    "        T = batch[3].cuda()\n",
    "        near_far_max_splatting_size = batch[5]\n",
    "        num_points = batch[4]\n",
    "        point_indexes = batch[0]\n",
    "        target = batch[7].cuda()\n",
    "        inds = batch[6].cuda()\n",
    "        rgbs = batch[8].cuda()\n",
    "\n",
    "        res,depth,features,dir_in_world,rgb,m_point_features = model(in_points, K, T,\n",
    "                            near_far_max_splatting_size, num_points, rgbs, inds)\n",
    "\n",
    "        #fused_features = torch.cat([features,dir_in_world],dim = 1)\n",
    "        #feature_maps.append(fused_features.detach().cpu().half())\n",
    "        #tars.append((target.cpu()*255).byte())\n",
    "\n",
    "\n",
    "        #if i %100 == 0:\n",
    "        #    print(i,'/',len(test_loader))\n",
    "        i = i+1\n",
    "\n",
    "        if (i>0):\n",
    "            break\n",
    "            \n",
    "    #plt.figure(figsize=(10,10))\n",
    "    plt.imshow(res.detach().cpu()[0].permute(1,2,0)[:,:,0:3])\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    \n",
    "    import numpy as np\n",
    "    from scipy.spatial.transform import Rotation as R\n",
    "    def slerp(p0, p1, t):\n",
    "            omega = np.arccos(np.dot(p0/np.linalg.norm(p0), p1/np.linalg.norm(p1)))\n",
    "            so = np.sin(omega)+1e-4\n",
    "            return np.sin((1.0-t)*omega) / so * p0 + np.sin(t*omega)/so * p1\n",
    "\n",
    "    def gen_trajectories(T,num=3.0):\n",
    "        N = T.shape[0]\n",
    "        new_T = []\n",
    "        for i in range(1,N):\n",
    "            r0 = R.from_matrix(T[i-1,0:3,0:3])\n",
    "            r1 = R.from_matrix(T[i,0:3,0:3])\n",
    "\n",
    "            for t in np.arange(0.0, 1.0, 1.0/num):\n",
    "                n_t = np.zeros((4,4))\n",
    "                n_t[0:3,0:3] = R.from_quat(slerp(r0.as_quat(), r1.as_quat(), t)).as_matrix()\n",
    "                n_t[0:3,3] = (T[i,0:3,3] - T[i-1,0:3,3])*t + T[i-1,0:3,3]\n",
    "                n_t[3,3] = 1.0\n",
    "                new_T.append(n_t)\n",
    "        new_T = np.stack(new_T, axis=0)\n",
    "        return new_T\n",
    "\n",
    "    new_T = gen_trajectories(dataset.datasets[0].Ts[0:-1:4,:,:].numpy(),num=8)\n",
    "\n",
    "    index = 0\n",
    "\n",
    "    dx = 1\n",
    "\n",
    "    if not os.path.exists(os.path.join(model_path,'vis_%d'%epoch)):\n",
    "        os.mkdir(os.path.join(model_path,'vis_%d'%epoch))\n",
    "    #if not os.path.exists(os.path.join(model_path,'vis_mask_%d'%epoch)):\n",
    "    #    os.mkdir(os.path.join(model_path,'vis_mask_%d'%epoch))\n",
    "    #if not os.path.exists(os.path.join(model_path,'vis_depth_%d'%epoch)):\n",
    "    #    os.mkdir(os.path.join(model_path,'vis_depth_%d'%epoch))\n",
    "\n",
    "    #if not os.path.exists(os.path.join(model_path,'vis_compos_%d'%epoch)):\n",
    "    #    os.mkdir(os.path.join(model_path,'vis_compos_%d'%epoch))\n",
    "\n",
    "    sKs = []\n",
    "    sTs = []\n",
    "    frames_id = []\n",
    "\n",
    "\n",
    "    writer_raw_rgb = write_frames(os.path.join(os.path.join(model_path,'vis_%d'%epoch),'vis_frame%04d_gt.mp4'%index), cfg.INPUT.SIZE_TRAIN,fps=30, macro_block_size =8,quality=6)  # size is (width, height)\n",
    "    writer_raw_depth = write_frames(os.path.join(os.path.join(model_path,'vis_%d'%epoch),'vis_frame%04d_depth.mp4'%index), cfg.INPUT.SIZE_TRAIN,fps=30, macro_block_size =8,quality=6)  # size is (width, height)\n",
    "\n",
    "\n",
    "    writer_raw_rgb.send(None)\n",
    "    writer_raw_depth.send(None)\n",
    "\n",
    "\n",
    "    for index in range(1):\n",
    "        _,in_points, _,_,_,_,rgbs,_ =  dataset.__getitem__(index*dataset.datasets[0].Ts.size(0))\n",
    "\n",
    "\n",
    "        print('frame:',index)\n",
    "\n",
    "\n",
    "\n",
    "        for j in range(1):\n",
    "\n",
    "\n",
    "\n",
    "            #s_pos = (center - radius*v.numpy()  + up*radius*0.5*j + up*radius*0.2)\n",
    "\n",
    "\n",
    "            for i in tqdm(range(new_T.shape[0])):\n",
    "            #for i in range(longitude_step(j)):\n",
    "\n",
    "\n",
    "                #near_far_max_splatting_size = torch.tensor([[0.5000, 6.5000, 0.2]])\n",
    "\n",
    "                num_points = torch.Tensor([in_points.size(0)])\n",
    "                rgbs = rgbs.cuda()\n",
    "                #print(num_points)\n",
    "\n",
    "                in_points = in_points.cuda()\n",
    "\n",
    "\n",
    "\n",
    "                nR = new_T[i]\n",
    "\n",
    "                sTs.append(nR)\n",
    "                sKs.append(K[0].cpu().numpy())\n",
    "                frames_id.append('img_%04d_%d_%d.jpg'%(index,i,j))\n",
    "\n",
    "                T[0,:,:] = torch.Tensor(nR).cuda()\n",
    "                with torch.no_grad():\n",
    "                    res,depth,features,dir_in_world,rgb,m_point_features = model(in_points, K, T,\n",
    "                                        near_far_max_splatting_size, num_points, rgbs, inds)\n",
    "\n",
    "                img_t = res.detach().cpu()[0]\n",
    "                img_t[img_t>1.0] = 1.0\n",
    "                img_t[img_t<0] = 0\n",
    "\n",
    "\n",
    "                #mask_t[mask_t<0.95] = 0\n",
    "                #mask_t[mask_t>0] = 1\n",
    "\n",
    "                img_t[0:3,:,:] = img_t[0:3,:,:]\n",
    "                img = cv2.cvtColor(img_t.permute(1,2,0).numpy()*255.0,cv2.COLOR_BGR2RGB)\n",
    "                img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                img_depth = depth.detach().cpu()[0][0].numpy()\n",
    "                img_depth = img_depth *255/ np.max(img_depth)\n",
    "                img_depth = cv2.cvtColor(img_depth,cv2.COLOR_GRAY2RGB)\n",
    "                \n",
    "                \n",
    "\n",
    "\n",
    "                #pca_feature = feats_map_pca_projection(features[0].detach().cpu().numpy())\n",
    "                #m_point_features = m_point_features.transpose(0,1).detach().cpu().numpy()\n",
    "\n",
    "                #pca_p_feats =  feats_pca_projection(m_point_features)\n",
    "\n",
    "                #writer.add_image('vis/rendered', pca_feature.transpose(2,0,1), i)\n",
    "                #writer.add_mesh('vis/points', vertices = in_points.view(1,in_points.size(0),-1) ,colors = torch.Tensor(pca_p_feats).view(1,in_points.size(0),-1),global_step = i)\n",
    "\n",
    "                #cv2.imwrite(os.path.join(model_path,'vis_%d/img_%04d_%d_%d.jpg'%(epoch,index,i,j)),img)\n",
    "\n",
    "                if not os.path.exists(os.path.join(os.path.join(model_path,'vis_%d'%epoch), '%04d'% index)):\n",
    "                    os.mkdir(os.path.join(os.path.join(model_path,'vis_%d'%epoch), '%04d'% index))\n",
    "                #img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "                cv2.imwrite(os.path.join(os.path.join(os.path.join(model_path,'vis_%d'%epoch), '%04d'% index),'img_frame%04d_%04d.bmp'%(index,i)),img.astype(np.uint8))\n",
    "                \n",
    "\n",
    "\n",
    "                writer_raw_rgb.send(img.astype(np.uint8))\n",
    "\n",
    "\n",
    "\n",
    "                writer_raw_depth.send(img_depth.astype(np.uint8))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                del res\n",
    "                del depth\n",
    "                del features\n",
    "                del dir_in_world\n",
    "                del rgb\n",
    "                del img\n",
    "                torch.cuda.empty_cache()\n",
    "                #print(i,'/360')\n",
    "\n",
    "        with open(os.path.join(model_path,'Intrinsic_%d_gt.inf'%epoch), 'w') as f:\n",
    "            for i,camk in enumerate(sKs):\n",
    "                f.write('%d\\n'%i)\n",
    "                f.write('%f %f %f\\n %f %f %f\\n %f %f %f\\n' % tuple(camk.reshape(9).tolist()))\n",
    "                f.write('\\n')\n",
    "\n",
    "\n",
    "        with open(os.path.join(model_path,'CamPose_%d_gt.inf' %epoch), 'w') as f:\n",
    "            for i,camT in enumerate(sTs):\n",
    "                A = camT[0:3,:]\n",
    "                tmp = np.concatenate( [A[0:3,2].T, A[0:3,0].T,A[0:3,1].T,A[0:3,3].T])\n",
    "                f.write('%f %f %f %f %f %f %f %f %f %f %f %f\\n' % tuple(tmp.tolist()))\n",
    "\n",
    "        with open(os.path.join(model_path,'frames_%d_gt.inf' %epoch), 'w') as f:\n",
    "            for i,ids in enumerate(frames_id):\n",
    "                f.write('%s\\n' % ids)\n",
    "\n",
    "\n",
    "    writer_raw_rgb.close()\n",
    "    writer_raw_depth.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spiral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(model_path, epoch):\n",
    "    para_file = 'nr_model_%d.pth' % epoch\n",
    "\n",
    "\n",
    "    cfg.merge_from_file(os.path.join(model_path,'configs.yml'))\n",
    "    #cfg.INPUT.SIZE_TRAIN = [1000,750]\n",
    "    #cfg.INPUT.SIZE_TEST = [1000,750]\n",
    "    cfg.SOLVER.IMS_PER_BATCH = 1\n",
    "    #cfg.freeze()\n",
    "    \n",
    "    test_loader, dataset = make_data_loader(cfg, is_train=False)\n",
    "    \n",
    "    model = build_model(cfg, isTrain = False)\n",
    "    a = torch.load(os.path.join(model_path,para_file),map_location='cpu')\n",
    "    model.pcpr_parameters.setPointNum(a['pcpr_parameters.p_parameters'].size(1))\n",
    "    model.load_state_dict(a)\n",
    "    #model.eval()\n",
    "    model = model.cuda()\n",
    "    #optimizer = make_optimizer(cfg, model)\n",
    "    #model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\")\n",
    "    \n",
    "    feature_maps = []\n",
    "    tars = []\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    for batch in test_loader:\n",
    "        in_points = batch[1].cuda()\n",
    "        K = batch[2].cuda()\n",
    "        T = batch[3].cuda()\n",
    "        near_far_max_splatting_size = batch[5]\n",
    "        num_points = batch[4]\n",
    "        point_indexes = batch[0]\n",
    "        target = batch[7].cuda()\n",
    "        inds = batch[6].cuda()\n",
    "        rgbs = batch[8].cuda()\n",
    "\n",
    "        res,depth,features,dir_in_world,rgb,m_point_features = model(in_points, K, T,\n",
    "                            near_far_max_splatting_size, num_points, rgbs, inds)\n",
    "\n",
    "        #fused_features = torch.cat([features,dir_in_world],dim = 1)\n",
    "        #feature_maps.append(fused_features.detach().cpu().half())\n",
    "        #tars.append((target.cpu()*255).byte())\n",
    "\n",
    "\n",
    "        #if i %100 == 0:\n",
    "        #    print(i,'/',len(test_loader))\n",
    "        i = i+1\n",
    "\n",
    "        if (i>0):\n",
    "            break\n",
    "            \n",
    "    #plt.figure(figsize=(10,10))\n",
    "    plt.imshow(res.detach().cpu()[0].permute(1,2,0)[:,:,0:3])\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    _,in_points, _,_,_,_,rgbs,_ =  dataset.__getitem__(0)\n",
    "    center = torch.mean(in_points,dim=0).cpu()\n",
    "    up = -torch.mean(dataset.datasets[0].Ts[:,0:3,1],dim =0)\n",
    "    up = up / torch.norm(up)\n",
    "    radius = torch.norm(dataset.datasets[0].Ts[0,0:3,3] - center) *0.87\n",
    "\n",
    "    center = center + up*radius*0.1\n",
    "\n",
    "\n",
    "    #v = torch.tensor([0,0,-1], dtype=torch.float32)\n",
    "    v = dataset.datasets[0].Ts[0,0:3,3] - center\n",
    "    v = v / torch.norm(v)\n",
    "\n",
    "\n",
    "    s_pos = center + v * radius + up*radius*0.05\n",
    "\n",
    "    center = center.numpy()\n",
    "    up = up.numpy()\n",
    "    radius = radius.item()\n",
    "    s_pos = s_pos.numpy()\n",
    "\n",
    "    lookat = center - s_pos\n",
    "    lookat = lookat/np.linalg.norm(lookat)\n",
    "\n",
    "    xaxis = np.cross(lookat, up)\n",
    "    xaxis = xaxis / np.linalg.norm(xaxis)\n",
    "\n",
    "    import math\n",
    "    def rotate(angle):\n",
    "        #res = np.array([ [math.cos(angle), -math.sin(angle), 0],[ math.sin(angle),math.cos(angle),0],[0,0,1] ])\n",
    "        res = np.array([ [math.cos(angle), 0, math.sin(-angle)],[0,1,0],[ math.sin(-angle),0, math.cos(angle)]])\n",
    "        return res\n",
    "\n",
    "    def rodrigues_rotation_matrix(axis, theta):\n",
    "        axis = np.asarray(axis)\n",
    "        theta = np.asarray(theta)\n",
    "        axis = axis/math.sqrt(np.dot(axis, axis))\n",
    "        a = math.cos(theta/2.0)\n",
    "        b, c, d = -axis*math.sin(theta/2.0)\n",
    "        aa, bb, cc, dd = a*a, b*b, c*c, d*d\n",
    "        bc, ad, ac, ab, bd, cd = b*c, a*d, a*c, a*b, b*d, c*d\n",
    "        return np.array([[aa+bb-cc-dd, 2*(bc+ad), 2*(bd-ac)],\n",
    "                         [2*(bc-ad), aa+cc-bb-dd, 2*(cd+ab)],\n",
    "                         [2*(bd+ac), 2*(cd-ab), aa+dd-bb-cc]])\n",
    "\n",
    "    index = 0\n",
    "\n",
    "    dx = 1\n",
    "\n",
    "    if not os.path.exists(os.path.join(model_path,'vis_%d'%epoch)):\n",
    "        os.mkdir(os.path.join(model_path,'vis_%d'%epoch))\n",
    "    #if not os.path.exists(os.path.join(model_path,'vis_mask_%d'%epoch)):\n",
    "    #    os.mkdir(os.path.join(model_path,'vis_mask_%d'%epoch))\n",
    "    #if not os.path.exists(os.path.join(model_path,'vis_depth_%d'%epoch)):\n",
    "    #    os.mkdir(os.path.join(model_path,'vis_depth_%d'%epoch))\n",
    "\n",
    "    #if not os.path.exists(os.path.join(model_path,'vis_compos_%d'%epoch)):\n",
    "    #    os.mkdir(os.path.join(model_path,'vis_compos_%d'%epoch))\n",
    "\n",
    "    sKs = []\n",
    "    sTs = []\n",
    "    frames_id = []\n",
    "\n",
    "\n",
    "    latitde = 1\n",
    "\n",
    "    longitude_step = lambda x: int((1.0 - float(abs(x))/latitde)*120 + 40)\n",
    "\n",
    "\n",
    "    writer_raw_rgb = write_frames(os.path.join(os.path.join(model_path,'vis_%d'%epoch),'vis_frame%04d.mp4'%index), cfg.INPUT.SIZE_TRAIN,fps=30, macro_block_size =8,quality=6)  # size is (width, height)\n",
    "    writer_raw_depth = write_frames(os.path.join(os.path.join(model_path,'vis_%d'%epoch),'vis_frame%04d_depth.mp4'%index), cfg.INPUT.SIZE_TRAIN,fps=30, macro_block_size =8,quality=6)  # size is (width, height)\n",
    "    writer_raw_compose = write_frames(os.path.join(os.path.join(model_path,'vis_%d'%epoch),'vis_frame%04d_compose.mp4'%index), cfg.INPUT.SIZE_TRAIN,fps=30, macro_block_size =8,quality=6)  # size is (width, height)\n",
    "\n",
    "\n",
    "    writer_raw_rgb.send(None)\n",
    "    writer_raw_depth.send(None)\n",
    "    writer_raw_compose.send(None)\n",
    "\n",
    "\n",
    "    for index in range(1):\n",
    "        _,in_points, _,_,_,_,rgbs,_ =  dataset.__getitem__(index*dataset.datasets[0].Ts.size(0))\n",
    "\n",
    "\n",
    "        print('frame:',index)\n",
    "\n",
    "\n",
    "\n",
    "        for j in range(1):\n",
    "\n",
    "\n",
    "\n",
    "            #s_pos = (center - radius*v.numpy()  + up*radius*0.5*j + up*radius*0.2)\n",
    "\n",
    "\n",
    "            for i in trange(longitude_step(j)):\n",
    "            #for i in range(longitude_step(j)):\n",
    "\n",
    "\n",
    "                #near_far_max_splatting_size = torch.tensor([[0.5000, 6.5000, 0.2]])\n",
    "\n",
    "                num_points = torch.Tensor([in_points.size(0)])\n",
    "                rgbs = rgbs.cuda()\n",
    "                #print(num_points)\n",
    "\n",
    "                in_points = in_points.cuda()\n",
    "\n",
    "\n",
    "                angle_step = 180.0/ longitude_step(j)\n",
    "\n",
    "                angle = 3.1415926*4*i*angle_step/360.0\n",
    "\n",
    "                #angle= 0 \n",
    "                s_pos = (center + radius*v.numpy()  + up*radius*0.0*math.sin(3.1415926*2*i/longitude_step(j)) + up*radius*0.05)\n",
    "                pos = s_pos - center\n",
    "                pos = rodrigues_rotation_matrix(up,-angle).dot(pos) \n",
    "\n",
    "                pos = pos + center\n",
    "\n",
    "                #print('pos:',pos)\n",
    "\n",
    "\n",
    "                lookat = center - pos\n",
    "                lookat = lookat/np.linalg.norm(lookat)\n",
    "\n",
    "                xaxis = np.cross(lookat, up)\n",
    "                xaxis = xaxis / np.linalg.norm(xaxis)\n",
    "\n",
    "                yaxis = -np.cross(xaxis,lookat)\n",
    "                yaxis = yaxis/np.linalg.norm(yaxis)\n",
    "\n",
    "                nR = np.array([xaxis,yaxis,lookat, pos]).T\n",
    "                nR = np.concatenate([nR,np.array([[0,0,0,1]])])\n",
    "\n",
    "                sTs.append(nR)\n",
    "                sKs.append(K[0].cpu().numpy())\n",
    "                frames_id.append('img_%04d_%d_%d.jpg'%(index,i,j))\n",
    "\n",
    "                T[0,:,:] = torch.Tensor(nR).cuda()\n",
    "                with torch.no_grad():\n",
    "                    res,depth,features,dir_in_world,rgb,m_point_features = model(in_points, K, T,\n",
    "                                        near_far_max_splatting_size, num_points, rgbs, inds)\n",
    "\n",
    "                img_t = res.detach().cpu()[0]\n",
    "                img_t[img_t>1.0] = 1.0\n",
    "                img_t[img_t<0] = 0\n",
    "\n",
    "\n",
    "                #mask_t[mask_t<0.95] = 0\n",
    "                #mask_t[mask_t>0] = 1\n",
    "\n",
    "                img_t[0:3,:,:] = img_t[0:3,:,:]\n",
    "                img = cv2.cvtColor(img_t.permute(1,2,0).numpy()*255.0,cv2.COLOR_BGR2RGB)\n",
    "                img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                img_depth = depth.detach().cpu()[0][0].numpy()\n",
    "                img_depth = img_depth *255/ np.max(img_depth)\n",
    "                img_depth = cv2.cvtColor(img_depth,cv2.COLOR_GRAY2RGB)\n",
    "                \n",
    "                depth_mask = depth[:,0:1,:,:].detach().cpu().clone()\n",
    "                depth_mask[depth_mask>0] = 1\n",
    "                depth_mask = torch.clamp(depth_mask,0,1.0).repeat(1,3,1,1)\n",
    "\n",
    "                #pca_feature = feats_map_pca_projection(features[0].detach().cpu().numpy())\n",
    "                #m_point_features = m_point_features.transpose(0,1).detach().cpu().numpy()\n",
    "\n",
    "                #pca_p_feats =  feats_pca_projection(m_point_features)\n",
    "\n",
    "                #writer.add_image('vis/rendered', pca_feature.transpose(2,0,1), i)\n",
    "                #writer.add_mesh('vis/points', vertices = in_points.view(1,in_points.size(0),-1) ,colors = torch.Tensor(pca_p_feats).view(1,in_points.size(0),-1),global_step = i)\n",
    "\n",
    "                #cv2.imwrite(os.path.join(model_path,'vis_%d/img_%04d_%d_%d.jpg'%(epoch,index,i,j)),img)\n",
    "\n",
    "                if not os.path.exists(os.path.join(os.path.join(model_path,'vis_%d'%epoch), '%04d'% index)):\n",
    "                    os.mkdir(os.path.join(os.path.join(model_path,'vis_%d'%epoch), '%04d'% index))\n",
    "                #img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "               \n",
    "\n",
    "                \n",
    "                writer_raw_rgb.send(img.astype(np.uint8))\n",
    "                \n",
    "                #print((img_t*depth_mask).size())\n",
    "                img_mask = (depth_mask)[0].permute(1,2,0)\n",
    "                \n",
    "                img_mask = cv2.cvtColor(img_mask.numpy()*255.0,cv2.COLOR_BGR2RGB)\n",
    "                img_mask = cv2.cvtColor(img_mask,cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                img_mask = img_mask.astype(np.uint8)\n",
    "                \n",
    "                kernel = np.ones((5,5),np.uint8)\n",
    "                closing = cv2.morphologyEx(img_mask, cv2.MORPH_CLOSE, kernel)\n",
    "                \n",
    "                closing[closing>240] = 255\n",
    "                closing[closing<255] = 0\n",
    "                \n",
    "                cv2.imwrite(os.path.join(os.path.join(os.path.join(model_path,'vis_%d'%epoch), '%04d'% index),'img_frame%04d_%04d.jpg'%(index,i)),img.astype(np.uint8))\n",
    "                cv2.imwrite(os.path.join(os.path.join(os.path.join(model_path,'vis_%d'%epoch), '%04d'% index),'img_frame%04d_%04d_mask.jpg'%(index,i)),closing)\n",
    "\n",
    "\n",
    "\n",
    "                writer_raw_depth.send(closing.astype(np.uint8))\n",
    "                \n",
    "                img[closing<200] = 255\n",
    "                writer_raw_compose.send(img.astype(np.uint8))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                del res\n",
    "                del depth\n",
    "                del features\n",
    "                del dir_in_world\n",
    "                del rgb\n",
    "                del img\n",
    "                torch.cuda.empty_cache()\n",
    "                #print(i,'/360')\n",
    "\n",
    "        with open(os.path.join(model_path,'Intrinsic_%d.inf'%epoch), 'w') as f:\n",
    "            for i,camk in enumerate(sKs):\n",
    "                f.write('%d\\n'%i)\n",
    "                f.write('%f %f %f\\n %f %f %f\\n %f %f %f\\n' % tuple(camk.reshape(9).tolist()))\n",
    "                f.write('\\n')\n",
    "\n",
    "\n",
    "        with open(os.path.join(model_path,'CamPose_%d.inf' %epoch), 'w') as f:\n",
    "            for i,camT in enumerate(sTs):\n",
    "                A = camT[0:3,:]\n",
    "                tmp = np.concatenate( [A[0:3,2].T, A[0:3,0].T,A[0:3,1].T,A[0:3,3].T])\n",
    "                f.write('%f %f %f %f %f %f %f %f %f %f %f %f\\n' % tuple(tmp.tolist()))\n",
    "\n",
    "        with open(os.path.join(model_path,'frames_%d.inf' %epoch), 'w') as f:\n",
    "            for i,ids in enumerate(frames_id):\n",
    "                f.write('%s\\n' % ids)\n",
    "\n",
    "\n",
    "    writer_raw_rgb.close()\n",
    "    writer_raw_depth.close()    \n",
    "    writer_raw_compose.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle = 3.1415926*2*i/360.0\n",
    "\n",
    "pos = s_pos - center\n",
    "pos = rodrigues_rotation_matrix(up,-angle).dot(pos) \n",
    "pos = pos + center\n",
    "\n",
    "print(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = features.detach()[0].cpu().numpy().transpose(1,2,0)\n",
    "print(feats.shape)\n",
    "feats = np.reshape(feats,(-1,32))\n",
    "print(feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.mat(feats.T)\n",
    "data_mean = data - data.mean(axis=1)\n",
    "data_cov = np.cov(data_mean)\n",
    "tzz,tzxl = np.linalg.eig(data_cov)\n",
    "\n",
    "xl = tzxl.T[0:3]\n",
    "\n",
    "res =  data_mean.T.__mul__(np.mat(xl).T)\n",
    "\n",
    "res = res/np.std(res) + 0.5\n",
    "res = np.array(res)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res.reshape((600,800,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,16))\n",
    "plt.imshow(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T1 =  np.vstack( [np.array([ -0.991663, -0.075813, 0.104196, 0.062654, -0.990274, -0.124229, 0.112601, -0.116665, 0.986768,-0.315234 ,-0.048224, -7.282628]).reshape(4,3).T, np.array([0,0,0,1])])\n",
    "T2 = np.vstack( [np.array([0.291734, 0.239859, -0.925937, 0.109816, 0.953247, 0.281534, 0.950174 ,-0.183816, 0.251754 , -4.038317, -0.059477, 4.109609]).reshape(4,3).T, np.array([0,0,0,1])])\n",
    "Ts = T2.dot(np.linalg.inv(T1))\n",
    "print(Ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(dataset),dataset.frame_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def rodrigues_rotation_matrix(axis, theta):\n",
    "    axis = np.asarray(axis)\n",
    "    theta = np.asarray(theta)\n",
    "    axis = axis/math.sqrt(np.dot(axis, axis))\n",
    "    a = math.cos(theta/2.0)\n",
    "    b, c, d = -axis*math.sin(theta/2.0)\n",
    "    aa, bb, cc, dd = a*a, b*b, c*c, d*d\n",
    "    bc, ad, ac, ab, bd, cd = b*c, a*d, a*c, a*b, b*d, c*d\n",
    "    return np.array([[aa+bb-cc-dd, 2*(bc+ad), 2*(bd-ac)],\n",
    "                     [2*(bc-ad), aa+cc-bb-dd, 2*(cd+ab)],\n",
    "                     [2*(bd+ac), 2*(cd-ab), aa+dd-bb-cc]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(rodrigues_rotation_matrix([0,1,1],0.5))\n",
    "import numpy as np\n",
    "print(np.rad2deg(3.141592653))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_depth = depth.detach().cpu()[0][0].numpy()\n",
    "img_depth = img *255/ np.max(img_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(model_path,'Intrinsic_%d.inf'%epoch), 'w') as f:\n",
    "    for i,camk in enumerate(sKs):\n",
    "        f.write('%d\\n'%i)\n",
    "        f.write('%f %f %f\\n %f %f %f\\n %f %f %f\\n' % tuple(camk.reshape(9).tolist()))\n",
    "        f.write('\\n')\n",
    "        \n",
    "        \n",
    "with open(os.path.join(model_path,'CamPose_%d.inf' %epoch), 'w') as f:\n",
    "    for i,camT in enumerate(sTs):\n",
    "        A = camT[0:3,:]\n",
    "        tmp = np.concatenate( [A[0:3,2].T, A[0:3,0].T,A[0:3,1].T,A[0:3,3].T])\n",
    "        f.write('%f %f %f %f %f %f %f %f %f %f %f %f\\n' % tuple(tmp.tolist()))\n",
    "        \n",
    "\n",
    "        \n",
    "with open(os.path.join(model_path,'frames_%d.inf' %epoch), 'w') as f:\n",
    "    for i,ids in enumerate(frames_id):\n",
    "        f.write('%d\\n' % int(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_id =  np.array(frames_id).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(T[0,0:3,0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation as R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = R.from_matrix([[0, -1, 0],\n",
    "               [1, 0, 0],\n",
    "                [0, 0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = scipy.spatial.transform.Rotation([[0, -1, 0],\n",
    "               [1, 0, 0],\n",
    "                [0, 0, 1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.as_euler('xyz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "def slerp(p0, p1, t):\n",
    "        omega = np.arccos(np.dot(p0/np.linalg.norm(p0), p1/np.linalg.norm(p1)))\n",
    "        so = np.sin(omega)\n",
    "        return np.sin((1.0-t)*omega) / so * p0 + np.sin(t*omega)/so * p1\n",
    "\n",
    "def gen_trajectories(T,num=3.0):\n",
    "    N = T.shape[0]\n",
    "    new_T = []\n",
    "    for i in range(1,N):\n",
    "        key_rots = R.from_matrix(T[i-1:i+1,0:3,0:3])\n",
    "        key_times = [0, 1]\n",
    "        slerp = scipy.spatial.transform.Slerp(key_times, key_rots)\n",
    "        times = np.arange(0.0, 1.0, 1.0/num)\n",
    "        interp_rots = slerp(times)\n",
    "        \n",
    "        Rs = [i for i in interp_rots.as_matrix()]\n",
    "        \n",
    "        for t in np.arange(0.0, 1.0, 1.0/num):\n",
    "            n_t = np.zeros((4,4))\n",
    "            n_t[0:3,0:3] = i\n",
    "            n_t[0:3,3] = (T[i,0:3,3] - T[i-1,0:3,3])*t + T[i-1,0:3,3]\n",
    "            n_t[3,3] = 1.0\n",
    "            new_T.append(n_t)\n",
    "    new_T = np.stack(new_T, axis=0)\n",
    "    return new_T\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_trajectories(dataset.datasets[0].Ts[0:2,:,:].numpy(),num=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = R.random(5, random_state=2342345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in p:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
